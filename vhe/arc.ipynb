{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PixelCNN:\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, utils\n",
    "from pixelcnn.utils import * \n",
    "from pixelcnn.model import * \n",
    "from PIL import Image\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "#VHE:\n",
    "from builtins import super\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.distributions.normal import Normal\n",
    "import math\n",
    "\n",
    "from vhe import VHE, DataLoader, Transform\n",
    "from arc_loader import ArcDataset\n",
    "\n",
    "#######pixelcnn options #########\n",
    "parser = argparse.ArgumentParser()\n",
    "# data I/O\n",
    "parser.add_argument('-i', '--data_dir', type=str,\n",
    "\t\t\t\t\tdefault='data', help='Location for the dataset')\n",
    "parser.add_argument('-d', '--dataset', type=str,\n",
    "\t\t\t\t\tdefault='omni', help='Can be either cifar|mnist|omni')\n",
    "# model\n",
    "parser.add_argument('-q', '--nr_resnet', type=int, default=4,\n",
    "\t\t\t\t\thelp='Number of residual blocks per stage of the model')\n",
    "parser.add_argument('-n', '--nr_filters', type=int, default=40,\n",
    "\t\t\t\t\thelp='Number of filters to use across the model. Higher = larger model.')\n",
    "parser.add_argument('-a', '--mode', type=str, default='softmax', choices=['logistic_mix', 'softmax', 'gaussian'])\n",
    "parser.add_argument('-m', '--nr_logistic_mix', type=int, default=None,\n",
    "\t\t\t\t\thelp='Number of logistic components in the mixture. Higher = more flexible model')\n",
    "parser.add_argument('-sm', '--nr_softmax_bins', type=int, default=2,\n",
    "\t\t\t\t\thelp='Number of softmax bins (use instead of nr_logistic_mix)')\n",
    "parser.add_argument('-l', '--lr', type=float,\n",
    "\t\t\t\t\tdefault=0.0002, help='Base learning rate')\n",
    "parser.add_argument('-e', '--lr_decay', type=float, default=0.999995,\n",
    "\t\t\t\t\thelp='Learning rate decay, applied every step of the optimization')\n",
    "parser.add_argument('-b', '--batch_size', type=int, default=8, #TODO change back to 32\n",
    "\t\t\t\t\thelp='Batch size during training per GPU')\n",
    "parser.add_argument('-x', '--max_epochs', type=int,\n",
    "\t\t\t\t\tdefault=5, help='How many epochs to run in total?')\n",
    "parser.add_argument('-s', '--seed', type=int, default=1,\n",
    "\t\t\t\t\thelp='Random seed to use')\n",
    "parser.add_argument('-an', '--anneal', type=int, default=None,\n",
    "\t\t\t\t\thelp='number of epochs to anneal')\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "\t\t\t\t\thelp='if the number of batches is small')\n",
    "parser.add_argument('--ortho', dest='ortho_transforms', action='store_true')\n",
    "parser.add_argument('--affine', action='store_true')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.nr_logistic_mix is None and args.nr_softmax_bins is None:\n",
    "\targs.nr_logistic_mix = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# reproducibility\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "sample_batch_size = args.batch_size\n",
    "obs = (10, 32, 32) \n",
    "rescaling\t = lambda x : (x - .5) * 2.\n",
    "flip = lambda x : - x\n",
    "kwargs = {'num_workers':1, 'pin_memory':True, 'drop_last':True}\n",
    "loss_op = None; sample_op = None\n",
    "args.mode = \"logistic_mix\"\n",
    "assert args.mode == \"logistic_mix\"\n",
    "\n",
    "if args.mode==\"logistic_mix\":\n",
    "\tloss_op   = lambda real, fake : discretized_mix_logistic_loss_1d(real, fake)\n",
    "\tsample_op = lambda x : sample_from_discretized_mix_logistic_1d(x, args.nr_logistic_mix)\n",
    "elif args.mode==\"softmax\":\n",
    "\tloss_op   = lambda real, fake : softmax_loss_1d(real, fake)\n",
    "\tsample_op = lambda x : sample_from_softmax_1d(x)\n",
    "elif args.mode == \"gaussian\":\n",
    "\tloss_op   = lambda real, fake: gaussian_loss(real, fake)\n",
    "\tsample_op = lambda x: sample_from_gaussian(x)\n",
    "\n",
    "#######end pixelcnn options #########\n",
    "\n",
    "\n",
    "# --------- real my implementation ------------\n",
    "train_loader = torch.utils.data.DataLoader(ArcDataset(), batch_size=1, \n",
    "\t\t\t\t\t\tshuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(ArcDataset(train = False), batch_size=1, \n",
    "\t\t\t\t\t\tshuffle=True, **kwargs)\n",
    "\n",
    "# --------- self tuned arguments ---------------\n",
    "\n",
    "input_channels = 10\n",
    "n_inputs = 4 # size of D\n",
    "input_size = 32\n",
    "z_filter = 8\n",
    "c_filter = 4\n",
    "\n",
    "class Px(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.decov = nn.ConvTranspose2d(c_filter + z_filter, input_channels, 3)\n",
    "\t\tself.x_length = input_channels * input_size * input_size\n",
    "\t\tself.localization_mu = nn.Linear(self.x_length, self.x_length)\n",
    "\t\tself.localization_sigma = nn.Linear(self.x_length, self.x_length)\n",
    "\t\tself.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "\tdef forward(self, c, z, x = None):\n",
    "\t\t# c, z = B * C'H'W' 其中他们的 channel 数 C' 不相同\n",
    "\t\tc = c.reshape(-1, c_filter, 30, 30)\n",
    "\t\tz = z.reshape(-1, z_filter, 30, 30)\n",
    "\t\tcz = torch.cat((c, z), dim=1)\n",
    "\t\t# decov = (self.decov(cz)).reshape(-1, input_size, input_size, input_channels) # B * H * W * C\n",
    "\t\t# predict = torch.argmax(decov.Softmax(dim = 3), dim = 3)\n",
    "\t\tdecov = (self.decov(cz)) # B*C*H*W\n",
    "\t\tpred = self.log_softmax(decov) # softmax on color dimension \n",
    "\t\tif x is not None: # training stage\n",
    "\t\t\tcross_entropy = x * pred\n",
    "\t\t\tscore = cross_entropy.sum(dim=1).sum(dim=1).sum(dim=1)\n",
    "\t\telse: # sampling / generating stage\n",
    "\t\t\tx = F.one_hot(torch.argmax(pred, dim=1), num_classes = input_channels)\n",
    "\t\t\tscore = torch.zeros(sample_batch_size)\n",
    "\n",
    "\t\treturn x, score\n",
    "\n",
    "\t\t\n",
    "\t\t# mu, sigma = self.localization_mu(decov), self.localization_sigma(decov)\n",
    "\t\t# sigma = sigma.exp()\n",
    "\t\t# dist = Normal(mu, sigma)\n",
    "\t\t# if x is None:\n",
    "\t\t# \tx = dist.rsample()\n",
    "\t\t# x = x.reshape(-1, self.x_length)\n",
    "\t\t# score = dist.log_prob(x).sum(dim=1)\n",
    "\t\t# x = x.reshape(-1, input_channels, input_size, input_size)\n",
    "\t\t# return x, score\n",
    "\t\t\n",
    "class Qc(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Qc, self).__init__()\n",
    "\t\tself.kernel_size = 3\n",
    "\t\tself.stride = 1\n",
    "\t\tself.conv1 = nn.Conv2d(input_channels, c_filter, kernel_size = self.kernel_size, stride = self.stride)\n",
    "\t\tself.after1_size = (input_size - self.kernel_size + 1) // self.stride\n",
    "\t\tself.c_length = c_filter * self.after1_size* self.after1_size\n",
    "\t\tself.localization_mu = nn.Linear(self.c_length, self.c_length)\n",
    "\t\tself.localization_sigma = nn.Linear(self.c_length, self.c_length)\n",
    "\t\t\n",
    "\tdef forward(self, inputs, c = None):\n",
    "\t\t# inputs has the shape B * D * C * H * W\n",
    "\t\tbd = inputs.reshape(-1, input_channels, input_size, input_size) # BD * C * H * W\n",
    "\t\tconved = self.conv1(bd) # BD * C' * H' * W'\n",
    "\t\tchw = conved.reshape(-1, n_inputs, c_filter * self.after1_size* self.after1_size) # B * D * C'H'W'\n",
    "\t\tpooled = torch.max(chw.permute(0,2,1), dim = 2).values # B * C'H'W'\n",
    "\t\tmu, sigma = self.localization_mu(pooled), self.localization_sigma(pooled)\n",
    "\t\tsigma = sigma.exp() # make sure sigma is positive\n",
    "\t\tdist = Normal(mu, sigma)\n",
    "\t\tif c is None:\n",
    "\t\t\tc = dist.rsample()\n",
    "\t\tscore = dist.log_prob(c).sum(dim=1)\n",
    "\t\treturn c, score\n",
    "\t\t\n",
    "class Qz(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Qz, self).__init__()\n",
    "\t\tself.kernel_size = 3\n",
    "\t\tself.stride = 1\n",
    "\t\tself.conv1 = nn.Conv2d(input_channels, z_filter, kernel_size = self.kernel_size, stride = self.stride)\n",
    "\t\tself.after1_size = (input_size - self.kernel_size + 1) // self.stride\n",
    "\t\tself.z_length = z_filter * self.after1_size* self.after1_size\n",
    "\t\tself.localization_mu = nn.Linear(self.z_length, self.z_length)\n",
    "\t\tself.localization_sigma = nn.Linear(self.z_length, self.z_length)\n",
    "\n",
    "\t\n",
    "\tdef forward(self, inputs, c, z = None):\n",
    "\t\tinputs = inputs.reshape(-1, input_channels, input_size, input_size) # make sure it's B * C * H * W\n",
    "\t\tconved = self.conv1(inputs)\n",
    "\t\tchw = conved.reshape(-1, self.z_length) # B * C'H'W'\n",
    "\t\tmu, sigma = self.localization_mu(chw), self.localization_sigma(chw)\n",
    "\t\tsigma = sigma.exp() # make sure sigma is positive\n",
    "\t\tdist = Normal(mu, sigma)\n",
    "\t\tif z is None:\n",
    "\t\t\tz = dist.rsample()\n",
    "\t\tscore = dist.log_prob(z).sum(dim=1)\n",
    "\t\treturn z, score\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vhe = VHE(encoder=[Qc(), Qz()],\n",
    "\t\tdecoder=Px())\n",
    "vhe = vhe.cuda()\n",
    "print(\"created vhe\")\n",
    "print(\"number of parameters is\", sum(p.numel() for p in vhe.parameters() if p.requires_grad))\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "if args.debug:\n",
    "\tdata_cutoff = 50\n",
    "\tdata, class_labels = zip(*islice(train_loader, data_cutoff))\n",
    "else:\n",
    "\tdata_cutoff = None\n",
    "\tdata, class_labels = zip(*train_loader)\n",
    "\n",
    "data = torch.cat(data)\n",
    "\n",
    "\n",
    "batch_size = args.batch_size\n",
    "\n",
    "data_loader = DataLoader(data=data, labels = {'c':class_labels, 'z':range(len(data))},\n",
    "\t\tbatch_size=batch_size, k_shot= {'c': n_inputs, 'z': 1})#, transforms=[transform_small_affine, transform_ortho_affine])\n",
    "\n",
    "#test data:\n",
    "if data_cutoff is not None:\n",
    "\ttest_data, test_class_labels = zip(*islice(test_loader, data_cutoff))\n",
    "else:\n",
    "\ttest_data, test_class_labels = zip(*test_loader)\n",
    "test_data = torch.cat(test_data)\n",
    "print(\"test dataset size\", test_data.size())\n",
    "\n",
    "test_data_loader = DataLoader(data=test_data, labels = {'c':test_class_labels, 'z':range(len(test_data))},\n",
    "\t\tbatch_size=batch_size, k_shot= {'c': n_inputs, 'z': 1})\n",
    "\n",
    "\n",
    "# Training\n",
    "print(\"started training\")\n",
    "\n",
    "optimiser = optim.Adam(vhe.parameters(), lr=1e-3)\n",
    "scheduler = lr_scheduler.StepLR(optimiser, step_size=1, gamma=args.lr_decay)\n",
    "\n",
    "total_iter = 0\n",
    "for epoch in range(1, args.max_epochs):\n",
    "\n",
    "\tkl_factor = min((epoch-1)/args.anneal, 1) if args.anneal else 1\n",
    "\t\n",
    "\tprint(\"kl_factor:\", kl_factor)\n",
    "\tbatchnum = 0\n",
    "\tfor batch in data_loader:\n",
    "\t\t# batch.inputs['c'].shape == [batch_size, n_inputs, dim_of_the_pic]\n",
    "\t\t# batch.inputs['c'].shape == [32, 2, 10, 32, 32]\n",
    "\t\t# TODO should verify whether has the same input dim as example CNN or not\n",
    "\t\tinputs = {k:v.cuda() for k,v in batch.inputs.items()}\n",
    "\t\tsizes = batch.sizes\n",
    "\t\ttarget = batch.target.cuda()\n",
    "\n",
    "\t\toptimiser.zero_grad()\n",
    "\t\tscore, kl = vhe.score(inputs=inputs, sizes=sizes, x=target, return_kl=True, kl_factor=kl_factor)\n",
    "\t\t(-score).backward() \n",
    "\t\toptimiser.step()\n",
    "\t\tbatchnum += 1\n",
    "\t\tprint(\"Batch %d Score %3.3f KLc %3.3f KLz %3.3f\" % (batchnum, score.item(), kl.c.item(), kl.z.item()),flush=True)\n",
    "\t\ttotal_iter = total_iter + 1\n",
    "\tprint(\"---Epoch %d Score %3.3f KLc %3.3f KLz %3.3f\" % (epoch, score.item(), kl.c.item(), kl.z.item()))\n",
    "\n",
    "\tif epoch %5==0: \n",
    "\t\ttorch.save(vhe.state_dict(), './VHE_pixelCNN_epoch_{}.p'.format(epoch))\n",
    "\t\tprint(\"saved model\")\n",
    "\n",
    "\n",
    "\t\t#Sampling:\n",
    "\tfor batch in islice(test_data_loader, 1):\n",
    "\t\ttest_inputs = {k:v.cuda() for k,v in batch.inputs.items()}\n",
    "\t\tprint(\"\\nPosterior predictive for test inputs\")\n",
    "\t\tsampled_x = vhe.sample(inputs={'c':test_inputs['c']}).x \n",
    "\t\tsampled_result = np.array(torch.argmax(sampled_x, dim = 3), dtype = np.int32).tolist()\n",
    "\t\t# x_in = torch.tensor(test_inputs['c'])\n",
    "\t\t# x_out = torch.tensor(sampled_x)\n",
    "\t\t# x_in = np.array(torch.argmax(x_in, dim = 2), dtype = np.int32)\n",
    "\t\t# x_out = np.array(torch.argmax(x_out, dim = 1).numpy(), dtype = np.int32)\n",
    "\t\t# x_in_and_out = list(map(lambda a,b : {\"input\":a, \"output\":b}, zip(x_in,x_out)))\n",
    "\t\tx_in_and_out = list(map(lambda a : {\"input\":a, \"output\":a}, sampled_result))\n",
    "\t\twith open(\"samples_epoch_\" + str(epoch) + \".json\", 'w') as f:\n",
    "\t\t\tjson.dump({\"train\":x_in_and_out}, f)\n",
    "\n",
    "\t\t# torchvision.utils.save_image([test_inputs['c'][i,j,:,:,:] for j in range(n_inputs) for i in range(args.batch_size)] , \"sample_support_epoch_{}.png\".format(epoch), padding=5, pad_value=1, nrow=args.batch_size)\n",
    "\t\t# torchvision.utils.save_image(sampled_x, \"samples_epoch_{}.png\".format(epoch), padding=5, pad_value=1, nrow=args.batch_size)\n",
    "\n",
    "\n",
    "\t#do testing\n",
    "\tvhe.train()\n",
    "\n",
    "\t#may not want this, but can keep:\n",
    "\tscheduler.step()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
